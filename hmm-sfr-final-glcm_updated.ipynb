{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafdc78d-5386-4b88-9abe-409415f11df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "# Function to compute GLCM features for six properties across four directions\n",
    "def compute_glcm_features_4_directions(window, distances=[1], levels=256):\n",
    "    # Convert to grayscale if the window is not already\n",
    "    if len(window.shape) == 3:\n",
    "        window = cv2.cvtColor(window, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Ensure the window pixel intensity is in the range [0, levels-1]\n",
    "    window = np.clip(window, 0, levels - 1).astype(np.uint8)\n",
    "    \n",
    "    # Define angles for the four directions: 0°, 45°, 90°, 135°\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    \n",
    "    # Compute GLCM\n",
    "    glcm = graycomatrix(window, distances=distances, angles=angles, levels=levels, symmetric=True, normed=True)\n",
    "    \n",
    "    # Extract GLCM properties for six features\n",
    "    features = {}\n",
    "    features['contrast'] = np.mean(graycoprops(glcm, 'contrast'))\n",
    "    features['dissimilarity'] = np.mean(graycoprops(glcm, 'dissimilarity'))\n",
    "    features['homogeneity'] = np.mean(graycoprops(glcm, 'homogeneity'))\n",
    "    features['ASM'] = np.mean(graycoprops(glcm, 'ASM'))  # Angular Second Moment (Energy)\n",
    "    features['energy'] = np.mean(np.sqrt(graycoprops(glcm, 'ASM')))  # Energy is sqrt(ASM)\n",
    "    features['correlation'] = np.mean(graycoprops(glcm, 'correlation'))\n",
    "    \n",
    "    return [features['contrast'], features['dissimilarity'], features['homogeneity'], \n",
    "            features['ASM'], features['energy'], features['correlation']]\n",
    "\n",
    "# Load data from the Excel file\n",
    "labels_df = pd.read_excel(r'//home//jaykishor_c//final-model-training//line_gt 7.xlsx')  \n",
    "\n",
    "# Parameters\n",
    "window_width = 50  # Width of each sliding window in pixels\n",
    "step_size = 20     # Step size of the sliding window in pixels\n",
    "image_folder = r'//home//jaykishor_c//final-model-training//color_equlsize_jpg 2//color_equlsize_jpg'  \n",
    "\n",
    "# labels_df = pd.read_excel(r'//home//jaykishor_c//final-model-training//gt_WIndow .xlsx')\n",
    "# image_folder = r'//home//jaykishor_c//final-model-training//color_window_double1//color_window_double1' \n",
    "\n",
    "# Dictionary to store GLCM feature sequences for each character across all images\n",
    "character_glcm_sequences = {}\n",
    "\n",
    "# Process each image (word) in the dataset\n",
    "for index, row in labels_df.iterrows():\n",
    "    image_name = row['image name']          # image name of respective gt text\n",
    "    character_sequence = row['gt']          # gt text\n",
    "    \n",
    "    # Load the corresponding image\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Image {image_name} could not be loaded.\")\n",
    "        continue\n",
    "\n",
    "    image_width = image.shape[1]  # Get image width\n",
    "    \n",
    "    # Calculate the width of each character region based on the sequence length\n",
    "    num_characters = len(character_sequence)\n",
    "    character_width = image_width // num_characters\n",
    "    \n",
    "    # Loop through each character in the sequence and collect its GLCM features\n",
    "    for i, char in enumerate(character_sequence):\n",
    "        # Define the region corresponding to the current character\n",
    "        region_start = i * character_width\n",
    "        region_end = region_start + character_width\n",
    "        character_region = image[:, region_start:region_end]  # Assume height is all rows\n",
    "        \n",
    "        # Split the character region into windows to capture GLCM features\n",
    "        num_windows = (character_width - window_width) // step_size + 1\n",
    "        char_glcm_sequence = []\n",
    "        \n",
    "        for j in range(num_windows):\n",
    "            # Calculate the start and end of the window within the character region\n",
    "            window_start = region_start + j * step_size\n",
    "            window_end = window_start + window_width\n",
    "            \n",
    "            # Extract the window\n",
    "            window = image[:, window_start:window_end]\n",
    "            \n",
    "            # Compute GLCM features for this window across four directions\n",
    "            glcm_features = compute_glcm_features_4_directions(window)\n",
    "            char_glcm_sequence.append(glcm_features)\n",
    "        \n",
    "        # Append this character's GLCM features to the global dictionary\n",
    "        if char not in character_glcm_sequences:\n",
    "            character_glcm_sequences[char] = []\n",
    "        character_glcm_sequences[char].append(char_glcm_sequence)\n",
    "\n",
    "# Print the number of GLCM feature sequences for each character\n",
    "for char, sequences in character_glcm_sequences.items():\n",
    "    print(f\"Character '{char}'  has {len(sequences)}    sequences of GLCM features.\")\n",
    "\n",
    "# Save the GLCM features to a file for analysis\n",
    "output_path = r'character_glcm_features_final.xlsx'\n",
    "features_df = pd.DataFrame({\n",
    "    'Character': [char for char, sequences in character_glcm_sequences.items() for _ in sequences],\n",
    "    'GLCM Features': [seq for sequences in character_glcm_sequences.values() for seq in sequences]\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "features_df.to_excel(output_path, index=False)\n",
    "print(f\"GLCM features saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4085b45-7a0e-45b1-b218-15157f9d6f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(char_glcm_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1253bbc-4b94-4d95-a91a-3ab745c00f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from hmmlearn import hmm\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "\n",
    "# Dictionary to store character HMMs\n",
    "character_hmms = {}\n",
    "num_states = 4\n",
    "\n",
    "# Example: 'character_glcm_sequences' contains the GLCM feature sequences for each character\n",
    "for char, sequences in character_glcm_sequences.items():\n",
    "    # Remove empty sequences\n",
    "    sequences = [seq for seq in sequences if len(seq) > 0]\n",
    "    \n",
    "    if len(sequences) == 0:\n",
    "        print(f\"Warning: No valid sequences for character {char}. Skipping this character.\")\n",
    "        continue  # Skip to the next character if no valid sequences\n",
    "    \n",
    "    if len(sequences) >= 15:\n",
    "        # Prepare training data for the HMM\n",
    "        X = np.vstack(sequences)  # Stack the sequences into a single array\n",
    "        lengths = [len(seq) for seq in sequences]  # Length of each sequence\n",
    "\n",
    "        # Initialize HMM for this character\n",
    "        model = hmm.GaussianHMM(n_components=num_states, covariance_type=\"diag\", n_iter=1000, init_params='', verbose=True)\n",
    "\n",
    "\n",
    "        # Use the custom model\n",
    "        model.fit(X, lengths)\n",
    "\n",
    "        # Store the trained model\n",
    "        character_hmms[char] = model\n",
    "        print(f\"Model trained for character: {char}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.transmat_)  # View the transition matrix after training\n",
    "row_sums = model.transmat_.sum(axis=1)\n",
    "print(row_sums)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce45c3d-2dab-4e52-807d-edb090fb1886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import re\n",
    "\n",
    "# Assuming your models are in a dictionary called `character_hmms`\n",
    "# e.g., `character_hmms = {'െ': trained_model_1, 'ത': trained_model_2, ... }`\n",
    "\n",
    "def sanitize_filename(char):\n",
    "    # Replace invalid filename characters with an underscore or remove them\n",
    "    return re.sub(r'[<>:\"/\\\\|?*]', '_', char)\n",
    "\n",
    "for char, model in character_hmms.items():\n",
    "    # Sanitize character to create a valid filename\n",
    "    sanitized_char = sanitize_filename(char)\n",
    "    print(char,sanitized_char )\n",
    "    # Save the trained HMM model to a file with the sanitized name\n",
    "    joblib.dump(model, f\"{sanitized_char}_hmm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f925014-5afc-4987-88f4-aa8d39b2cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3413f6-76ff-4da4-96a2-54f516ca08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the character names (keys) from the character_hmms dictionary\n",
    "char_names = list(character_hmms.keys())\n",
    "\n",
    "# Print the character names\n",
    "print(\"Character names:\", char_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980a579d-e383-4211-aad2-a71538e6cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(char_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdef6ba-3aef-40a7-a8b1-8fa137ebd8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth =char_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65debf-54f4-4240-b4a2-ce8198070fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ground truth list:\", ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ffa1d-3466-4e63-85ef-469ef717253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the character names (keys) from the character_hmms dictionary\n",
    "char_names = list(character_hmms.keys())\n",
    "\n",
    "# Print the character names\n",
    "print(\"Character names:\", char_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fcbdd5-0a19-4424-a8ed-59da3ab9e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = sorted(set(\"\".join(ground_truth)))\n",
    "char_to_state = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "state_to_char = {idx: char for char, idx in char_to_state.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f0ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "\n",
    "characters_to_remove = ['ണ',' ൾ','ു','ഥ','ൃ','ബ','ൂഃ','ഃ','ൻ']\n",
    " \n",
    "# Calculate BLEU score for predictions\n",
    "for char, model in character_hmms.items():\n",
    "    try:\n",
    "        sequences = character_glcm_sequences[char]\n",
    "        # Remove empty sequences\n",
    "        sequences = [seq for seq in sequences if len(seq) > 0]\n",
    "        # Check if we have any sequences left\n",
    "        if len(sequences) >= 15:\n",
    "            X = np.vstack(sequences)\n",
    "            lengths = [len(seq) for seq in sequences]\n",
    "            # Check for valid transition matrix\n",
    "            row_sums = model.transmat_.sum(axis=1)\n",
    "            if not np.allclose(row_sums, 1):\n",
    "                print(f\"Problem with transition matrix for character '{char}': row sums = {row_sums}\")\n",
    "                characters_to_remove.append(char)\n",
    "                continue  # Skip this model and move to the next one\n",
    "            # Get predicted states\n",
    "            predicted_states = model.predict(X)\n",
    "            mapped_predictions = [state_to_char[state] for state in predicted_states]\n",
    "            # Calculate BLEU score\n",
    "            bleu_score = sentence_bleu([ground_truth], mapped_predictions)\n",
    "            print(f\"BLEU Score for character '{char}': {bleu_score}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error with character '{char}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabef850",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"These all character should be removed : {characters_to_remove}, becauses Problem with transition matrix for character, row sums = [0. 0. 0. 0.] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cdb4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of characters to remove from the character_hmms dictionary\n",
    "# Remove characters if they exist in the dictionary\n",
    "for char in characters_to_remove:\n",
    "    print (char)\n",
    "    if char in character_hmms:\n",
    "        del character_hmms[char]\n",
    "        print(f\"Deleted HMM model for character: {char}\")\n",
    "    else:\n",
    "        print(f\"Character {char} not found in character_hmms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa774b20-9ec8-4f15-a18f-f8b01b1a626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "\n",
    "# Calculate BLEU score for predictions (this is more useful for sequence generation tasks)\n",
    "for char, model in character_hmms.items():\n",
    "    sequences = character_glcm_sequences[char]\n",
    "    \n",
    "    # Remove empty sequences\n",
    "    sequences = [seq for seq in sequences if len(seq) > 0]\n",
    "    \n",
    "    # Check if we have any sequences left\n",
    "    if len(sequences) >=15:\n",
    "       \n",
    "        X = np.vstack(sequences)\n",
    "    \n",
    "    lengths = [len(seq) for seq in sequences]\n",
    "    \n",
    "    # Get predicted states\n",
    "    predicted_states = model.predict(X)\n",
    "    mapped_predictions = [state_to_char[state] for state in predicted_states]\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = sentence_bleu([ground_truth], mapped_predictions)\n",
    "print(f\"BLEU Score: {bleu_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19043a0-8640-4eb6-b6b2-66e320602aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each character and its model\n",
    "for char, model in character_hmms.items():\n",
    "    sequences = character_glcm_sequences[char]\n",
    "    \n",
    "    # Remove empty sequences\n",
    "    sequences = [seq for seq in sequences if len(seq) > 0]\n",
    "    \n",
    "    # Check if we have enough sequences to proceed\n",
    "    if len(sequences) >= 15:\n",
    "        X = np.vstack(sequences)\n",
    "\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        \n",
    "        # Get predicted states and map to characters\n",
    "        predicted_states = model.predict(X)\n",
    "        mapped_predictions = [state_to_char[state] for state in predicted_states]\n",
    "        \n",
    "        # Calculate BLEU score\n",
    "        bleu_score = sentence_bleu([ground_truth], mapped_predictions)\n",
    "        \n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'Character': char,\n",
    "            'Mapped Predictions': ''.join(mapped_predictions),\n",
    "            'BLEU Score': bleu_score\n",
    "        })\n",
    "\n",
    "# Create a DataFrame to store results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Save the results to an Excel file\n",
    "output_path = r'mapped_predictions_bleu_scores_hog.xlsx'\n",
    "results_df.to_excel(output_path, index=False)\n",
    "print(f\"Results saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a993d44-bc82-4911-a586-446626c00fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e85983e-9dee-44f3-9a65-28e5df0a7af3",
   "metadata": {},
   "source": [
    "**Log Probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fa9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for char, model in character_hmms.items():\n",
    "    sequences = character_glcm_sequences[char]\n",
    "    sequences = [seq for seq in sequences if len(seq) > 0]\n",
    "\n",
    "    if len(sequences) >= 15:\n",
    "        X = np.vstack(sequences)\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        log_probability = model.score(X, lengths)\n",
    "        print(f\"Log Probability for character '{char}': {log_probability}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b2eb66",
   "metadata": {},
   "source": [
    "**Model Probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc9ee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for char, model in character_hmms.items():\n",
    "    sequences = character_glcm_sequences[char]\n",
    "    sequences = [seq for seq in sequences if len(seq) > 0]\n",
    "\n",
    "    if len(sequences) >= 15:\n",
    "        X = np.vstack(sequences)\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        log_probability = model.score(X, lengths)\n",
    "        model_probability = np.exp(log_probability)  # Convert to regular probability\n",
    "        print(f\"Model Probability for character '{char}': {model_probability}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90404c69",
   "metadata": {},
   "source": [
    "**Transition Matrix Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for char, model in character_hmms.items():\n",
    "    row_sums = model.transmat_.sum(axis=1)\n",
    "    if not np.allclose(row_sums, 1):\n",
    "        print(f\"Transition matrix issue for '{char}': {row_sums}\")\n",
    "    else:\n",
    "        print(f\"Transition matrix for '{char}' is valid.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9472e4",
   "metadata": {},
   "source": [
    "**Emission Probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db143a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for char, model in character_hmms.items():\n",
    "    print(f\"Emission means for character '{char}': {model.means_}\")\n",
    "    print(f\"Emission covariances for character '{char}': {model.covars_}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672e96c",
   "metadata": {},
   "source": [
    "**Per-State Log Probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3c1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for char, model in character_hmms.items():\n",
    "    sequences = character_glcm_sequences[char]\n",
    "    sequences = [seq for seq in sequences if len(seq) > 0]\n",
    "\n",
    "    if len(sequences) >= 15:\n",
    "        X = np.vstack(sequences)  # Combine all sequences into a single array\n",
    "\n",
    "        # Use score_samples to compute posterior probabilities for states\n",
    "        log_prob, posteriors = model.score_samples(X)\n",
    "        print(f\"Log probabilities for character '{char}': {log_prob}\")\n",
    "        print(f\"Posterior probabilities for states:\\n{posteriors}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287030e",
   "metadata": {},
   "source": [
    "**Actual vs Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2df7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store actual vs predicted characters\n",
    "results = {'Actual': [], 'Predicted': []}\n",
    " \n",
    "# Process each test character and its sequences\n",
    "for actual_char, test_sequences in character_glcm_sequences.items():\n",
    "    for test_sequence in test_sequences:\n",
    "        test_sequence = np.array(test_sequence)\n",
    "        # Dictionary to store scores for each character model\n",
    "        scores = {}\n",
    "        # Score the test sequence against each character's HMM model\n",
    "        for char, model in character_hmms.items():\n",
    "            try:\n",
    "                scores[char] = model.score(test_sequence)\n",
    "            except:\n",
    "                scores[char] = -np.inf  # If model can't score, assign a low score\n",
    "        # Predict the character with the highest score\n",
    "        predicted_char = max(scores, key=scores.get)\n",
    "        # Store the result\n",
    "        results['Actual'].append(actual_char)\n",
    "        results['Predicted'].append(predicted_char)\n",
    " \n",
    "# Save the results to an Excel file\n",
    "output_path = r'actual_vs_predicted.xlsx'\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum([1 for actual, predicted in zip(results['Actual'], results['Predicted']) if actual == predicted])\n",
    "total_predictions = len(results['Actual'])\n",
    "accuracy = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "print(f\"Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e583f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaykishorEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
